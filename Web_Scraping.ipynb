{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium webdriver-manager beautifulsoup4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdAwzGeCDbft",
        "outputId": "0b86f33c-9c29-4cca-f8f7-87f75b9d5eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.29.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting webdriver-manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.1.31)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (2.32.3)\n",
            "Collecting python-dotenv (from webdriver-manager)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (24.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (3.4.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Downloading selenium-4.29.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, python-dotenv, outcome, webdriver-manager, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 python-dotenv-1.0.1 selenium-4.29.0 trio-0.29.0 trio-websocket-0.12.2 webdriver-manager-4.0.2 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import files\n",
        "\n",
        "# Definir la URL base de búsqueda en eBay con paginación\n",
        "search_url = \"https://www.ebay.com/sch/i.html?_nkw={}&_sop=12&_pgn={}\"\n",
        "\n",
        "# Lista de términos de búsqueda ampliada para obtener más productos\n",
        "search_terms = [\"electronics\", \"home decor\", \"clothing\", \"toys\", \"beauty products\", \"kitchen appliances\", \"sports equipment\", \"books\", \"automotive accessories\", \"gaming\", \"smartphones\", \"watches\", \"furniture\", \"office supplies\", \"pet supplies\"]\n",
        "\n",
        "# Número de páginas a recorrer por cada término de búsqueda\n",
        "num_pages = 20  # Aumentado para obtener más observaciones\n",
        "\n",
        "# Lista para almacenar los productos\n",
        "productos = []\n",
        "\n",
        "# Headers para evitar bloqueos por parte de eBay\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "for term in search_terms:\n",
        "    for page in range(1, num_pages + 1):\n",
        "        url = search_url.format(term.replace(\" \", \"+\"), page)\n",
        "        response = requests.get(url, headers=headers)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "            for producto in soup.find_all(\"li\", class_=\"s-item\"):\n",
        "                try:\n",
        "                    nombre_tag = producto.find(\"h3\", class_=\"s-item__title\")\n",
        "                    if not nombre_tag or \"Shop on eBay\" in nombre_tag.text:\n",
        "                        continue  # Omitir elementos sin nombre válido\n",
        "                    nombre = nombre_tag.text.strip()\n",
        "\n",
        "                    precio_tag = producto.find(\"span\", class_=\"s-item__price\")\n",
        "                    precio = precio_tag.text.strip() if precio_tag else \"N/A\"\n",
        "\n",
        "                    categoria = term.title()\n",
        "                    disponibilidad = \"Disponible\"\n",
        "\n",
        "                    ventas_tag = producto.find(\"span\", class_=\"s-item__hotness\")\n",
        "                    ventas = ventas_tag.text.strip() if ventas_tag else \"N/A\"\n",
        "\n",
        "                    num_resenas_tag = producto.find(\"span\", class_=\"s-item__reviews-count\")\n",
        "                    num_resenas = num_resenas_tag.text.strip() if num_resenas_tag else \"N/A\"\n",
        "\n",
        "                    calificacion_tag = producto.find(\"div\", class_=\"x-star-rating\")\n",
        "                    calificacion = calificacion_tag.text.strip() if calificacion_tag else \"N/A\"\n",
        "\n",
        "                    # Extraer unidades vendidas\n",
        "                    unidades_vendidas_tag = producto.find(\"span\", class_=\"s-item__quantitySold\")\n",
        "                    unidades_vendidas = unidades_vendidas_tag.text.strip() if unidades_vendidas_tag else \"N/A\"\n",
        "\n",
        "                    # Extraer tiempo de entrega estimado\n",
        "                    tiempo_entrega_tag = producto.find(\"span\", class_=\"s-item__logisticsCost\")\n",
        "                    tiempo_entrega = tiempo_entrega_tag.text.strip() if tiempo_entrega_tag else \"N/A\"\n",
        "\n",
        "                    # Extraer número de watchers (personas interesadas en el producto)\n",
        "                    watchers_tag = producto.find(\"span\", class_=\"s-item__watchCount\")\n",
        "                    watchers = watchers_tag.text.strip() if watchers_tag else \"N/A\"\n",
        "\n",
        "                    productos.append([nombre, categoria, precio, disponibilidad, ventas, num_resenas, calificacion, unidades_vendidas, tiempo_entrega, watchers])\n",
        "                except AttributeError:\n",
        "                    continue\n",
        "        else:\n",
        "            print(f\"Error al acceder a {url}, código de estado: {response.status_code}\")\n",
        "\n",
        "        # Espera aleatoria para evitar bloqueos\n",
        "        time.sleep(random.uniform(1, 3))\n",
        "\n",
        "# Guardar en CSV\n",
        "csv_filename = \"inventario_ebay_extendido.csv\"\n",
        "df = pd.DataFrame(productos, columns=[\"Nombre\", \"Categoría\", \"Precio\", \"Disponibilidad\", \"Ventas Recientes\", \"Número de Reseñas\", \"Calificación Promedio\", \"Unidades Vendidas\", \"Tiempo de Entrega\", \"Watchers\"])\n",
        "df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
        "\n",
        "# Verificar si hay datos antes de intentar descargar\n",
        "if not df.empty:\n",
        "    print(f\"Datos guardados en {csv_filename} con {len(df)} registros.\")\n",
        "    files.download(csv_filename)\n",
        "else:\n",
        "    print(\"No se encontraron productos. eBay podría estar bloqueando el scraping.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9hn9PEkCTHo",
        "outputId": "0ddf8e1e-b282-454e-cca3-4e77c2d477a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No se encontraron productos. eBay podría estar bloqueando el scraping.\n"
          ]
        }
      ]
    }
  ]
}